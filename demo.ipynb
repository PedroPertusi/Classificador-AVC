{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import autograd.numpy as np_   # Thinly-wrapped version of Numpy\n",
    "from autograd import grad\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### leitura do dataframe e remover os NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv')\n",
    "df = df[df['bmi'].notna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Poda do DATAFRAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### df de features e df de outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
    "df_features = pd.get_dummies(df_features)\n",
    "df_outcome = df[['stroke']]\n",
    "df_outcome = df_outcome.replace(0,-1)\n",
    "df_outcome = pd.get_dummies(df_outcome)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### df de treino e df de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_outcome, train_size=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### montando o predidor de árvore e estimando valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree = tree.fit(X_train, y_train)\n",
    "\n",
    "y_estimado = tree.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calculando a acurácia do nosso predidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9291242362525458"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur = accuracy_score(y_estimado,y_test)\n",
    "accur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hipotese nula (acurácia de um predidor que só chuta -1 (sem stroke))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584521384928717"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_so_0 = np.array([-1 for i in range(len(y_estimado))])\n",
    "accur_0 = accuracy_score(y_so_0,y_test)\n",
    "accur_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fatores que mais provavelmente estão ligados a ter AVCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "avg_glucose_level\n",
      "bmi\n",
      "hypertension\n",
      "work_type_Private\n"
     ]
    }
   ],
   "source": [
    "importances = tree.feature_importances_\n",
    "importances_indices = np.argsort(importances)[::-1]\n",
    "importances_indices = importances_indices[:5]\n",
    "\n",
    "colunas = list(df_features.head(0))\n",
    "\n",
    "for i in range(5):\n",
    "    print(colunas[importances_indices[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### árvore sem poda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plot_tree(tree, filled=True, rounded=True, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com poda do DATAFRAME (balancemaento de dados para strokes e para não strokes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### podando o dataframe (dx mesma qntd de dados de avc e não avc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.concat([df[df['stroke'] == 0].head(len(df[df['stroke'] == 1])), df[df['stroke'] == 1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### df de features e df de outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_p[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
    "df_features = pd.get_dummies(df_features)\n",
    "df_outcome = df_p[['stroke']].replace(0,-1)\n",
    "df_outcome = pd.get_dummies(df_outcome)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### df de treino e df de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_outcome, train_size=0.5)\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### montando o predidor de árvore e estimando valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree = tree.fit(X_train, y_train)\n",
    "\n",
    "y_estimado = tree.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calculando a acurácia do nosso predidor com poda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6555023923444976"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur = accuracy_score(y_estimado,y_test)\n",
    "accur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hipotese nula (acurácia de um predidor que só chuta -1 (sem stroke))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263157894736842"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_so_0 = np.array([-1 for i in range(len(y_estimado))])\n",
    "accur_0 = accuracy_score(y_so_0,y_test)\n",
    "accur_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fatores que mais provavelmente estão ligados a ter AVCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "avg_glucose_level\n",
      "bmi\n",
      "smoking_status_never smoked\n",
      "heart_disease\n"
     ]
    }
   ],
   "source": [
    "importances = tree.feature_importances_\n",
    "importances_indices = np.argsort(importances)[::-1]\n",
    "importances_indices = importances_indices[:5]\n",
    "\n",
    "colunas = list(df_features.head(0))\n",
    "\n",
    "for i in range(5):\n",
    "    print(colunas[importances_indices[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa abaixo, ocorre a implementação de um algoritmo de treinamento por meio de regressão linear utilizando gradiente descendente para encontrar os valores ótimos dos parâmetros w (vetor de pesos) e b (bias).\n",
    "\n",
    "A primeira função utilizada pelo algoritmo é a \"loss\". Esse método recebe de um conjunto de parâmetros w, b e pontos para calcular um Y estimado, ou seja, gerar um previsão. Isso occore por meio de um cálculo semelhante a uma função de primeiro grau, sendo w um vetor de coefientes ângulares e b um coeficiente linear. Logo após gerar uma previsão, utiliza o parametro val para calcular o MSE: Média dos erros quadráticos entre previsão e valor alvo. Por fim, retorna esse MSE.\n",
    "\n",
    "A função \"grad\" é usada para calcular o gradiente da função loss em relação aos parâmetros w e b. O gradiente é uma medida da inclinação da função de perda em relação aos parâmetros do modelo. O gradiente nos fornece a direção na qual a função de perda está aumentando mais rapidamente. No caso do gradiente descendente, usamos essa informação para atualizar os parâmetros do modelo na direção oposta ao gradiente, de modo que a função de perda seja minimizada.\n",
    "\n",
    "Define-se o conjunto de treinamento X e os valores alvo Y. O vetor de pesos w é inicializado aleatoriamente, e o bias b é definido como 0.5. O valor do hiperparâmetro alpha é definido como 10^-5.\n",
    "\n",
    "Em seguida, o código entra em um loop de treinamento, que executa o gradiente descendente por 10000 iterações. Em cada iteração, o gradiente da função loss é calculado com os parâmetros atuais (w, b, X, Y) usando a função grad, para assim, atualizar os pesos w e o bias b usando o resultado do gradiente e o valor de alpha.\n",
    "\n",
    "Por fim, calcula-se as previsões y_est para o conjunto X teste usando os valores finais dos parâmetros w e b. Em seguida, a acurácia das previsões é calculada usando a função accuracy, por meio da proporção entre previsões certas e erradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Extração e Tratamento dos dados. Foram levados em consideração apenas os dados capazer de serem transformados em booleanos'''\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv')\n",
    "df = df[df['bmi'].notna()]\n",
    "df = pd.concat([df[df['stroke'] == 0].head(len(df[df['stroke'] == 1])), df[df['stroke'] == 1]])\n",
    "\n",
    "df_features = df[['gender','hypertension','heart_disease','ever_married','work_type','Residence_type','smoking_status']]\n",
    "df_features = pd.get_dummies(df_features)\n",
    "df_outcome = df[['stroke']]\n",
    "df_outcome = df_outcome.replace(0,-1)\n",
    "df_outcome = pd.get_dummies(df_outcome)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_outcome, train_size=0.5)\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_est):\n",
    "    '''Função que calcula a precisão de um modelo de classificação binária.'''\n",
    "    return np.mean(np.sign(y_test)==np.sign(y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(parametros):\n",
    "    w, b, pontos, val = parametros\n",
    "    est = w.T @ pontos + b\n",
    "    mse = np_.mean((est - val)**2)\n",
    "    return mse\n",
    "\n",
    "g = grad(loss)\n",
    "\n",
    "X = (X_train.T).astype(float)\n",
    "Y = y_train.astype(float)\n",
    "\n",
    "w = np.random.randn(X.shape[0],1)\n",
    "b = 0.1\n",
    "alpha = 10**-5\n",
    "\n",
    "for n in range(10000):\n",
    "    grad_ = g((w, b, X, Y))\n",
    "    w -= alpha*grad_[0]\n",
    "    b -= alpha*grad_[1]\n",
    "\n",
    "y_est = w.T @ X + b\n",
    "pred = accuracy(y_test, y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo com regressão linear: 49.62%\n",
      "Acurácia da hipótese nula: 52.63%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acurácia do modelo com regressão linear: {pred*100:.2f}%\")\n",
    "print(f\"Acurácia da hipótese nula: {accur_0*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nossos testes, o desempenho do algoritmo de predição treinado por meio de regressão linear ficou próximo dos 50% de acurácia, semelhantemente ao resultado encotrado pela hipótese nula. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### O que mais impacta o DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ever_married_Yes\n",
      "gender_Male\n",
      "work_type_Private\n",
      "ever_married_No\n",
      "smoking_status_formerly smoked\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "mais_imp = []\n",
    "for i in range(5):\n",
    "    mais_imp.append(X.columns[np.argsort(w.T)[0][-i]])\n",
    "\n",
    "colunas = list(df_features.head(0))\n",
    "\n",
    "for i in range(5):\n",
    "    print(colunas[mais_imp[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
