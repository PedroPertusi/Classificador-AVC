{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import autograd.numpy as np_   # Thinly-wrapped version of Numpy\n",
    "from autograd import grad\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de Decisão"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa abaixo, ocorre a implementação de um algoritmo de treinamento por meio de árvore de decisão. \n",
    "\n",
    "Existem dois casos em que utilizamos a árvore de decisão, inicialmente sem nenhuma poda dos dados, e sucessivamente um com poda (50-50) que consiste em um dataframe equilibrado entre pessoas que apresentaram um AVC e pessoas que não. \n",
    "\n",
    "Em seguida, dividimos nossos dados em dois dataframes, um de features e outro de resultados, e então, utilizamos o mesmo com uma distribuição de 50% para treino e teste utilizando da função `train_test_split`.\n",
    "\n",
    "Em seguida, foi montada a árvore de decisões utilizando o `DecisionTreeClassifier` do pacote sklearn, e com o mesmo foi possível estimar para ambos os casos (com e sem poda dos dados). Com isso, analisamos nossos resultados levando em conta a hipótise nula que compôs cada caso.\n",
    "\n",
    "Finalmente, buscamos também encontrar os fatores que mais provavelmente estão ligados a ter AVCs em cada um de nossos classificadores (porém foi realizada uma melhor análise dos mesmos utilizando a árvore com poda no arquivo `DecisionTree10k.ipynb`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Poda do DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv')\n",
    "df = df[df['bmi'].notna()]\n",
    "df_features = df[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
    "df_features = pd.get_dummies(df_features)\n",
    "df_outcome = df[['stroke']]\n",
    "df_outcome = df_outcome.replace(0,-1)\n",
    "df_outcome = pd.get_dummies(df_outcome)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_outcome, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree = tree.fit(X_train, y_train)\n",
    "\n",
    "y_estimado = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 50.72%\n",
      "Acurácia da hipótese nula: 46.89%\n"
     ]
    }
   ],
   "source": [
    "accur = accuracy_score(y_estimado,y_test)\n",
    "print(f\"Acurácia do modelo: {accur*100:.2f}%\")\n",
    "y_so_0 = np.array([-1 for i in range(len(y_estimado))])\n",
    "accur_0 = accuracy_score(y_so_0,y_test)\n",
    "print(f\"Acurácia da hipótese nula: {accur_0*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fatores que mais provavelmente estão ligados a ter AVCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "avg_glucose_level\n",
      "bmi\n",
      "hypertension\n",
      "gender_Male\n"
     ]
    }
   ],
   "source": [
    "importances = tree.feature_importances_\n",
    "importances_indices = np.argsort(importances)[::-1]\n",
    "importances_indices = importances_indices[:5]\n",
    "\n",
    "colunas = list(df_features.head(0))\n",
    "\n",
    "for i in range(5):\n",
    "    print(colunas[importances_indices[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com poda do DATAFRAME (balancemaento de dados para strokes e para não strokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv')\n",
    "df = df[df['bmi'].notna()]\n",
    "df_p = pd.concat([df[df['stroke'] == 0].head(len(df[df['stroke'] == 1])), df[df['stroke'] == 1]])\n",
    "df_features = df_p[['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status']]\n",
    "df_features = pd.get_dummies(df_features)\n",
    "df_outcome = df_p[['stroke']].replace(0,-1)\n",
    "df_outcome = pd.get_dummies(df_outcome)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_outcome, train_size=0.5)\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree = tree.fit(X_train, y_train)\n",
    "\n",
    "y_estimado = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 50.72%\n",
      "Acurácia da hipótese nula: 46.89%\n"
     ]
    }
   ],
   "source": [
    "accur = accuracy_score(y_estimado,y_test)\n",
    "print(f\"Acurácia do modelo: {accur*100:.2f}%\")\n",
    "y_so_0 = np.array([-1 for i in range(len(y_estimado))])\n",
    "accur_0 = accuracy_score(y_so_0,y_test)\n",
    "print(f\"Acurácia da hipótese nula: {accur_0*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fatores que mais provavelmente estão ligados a ter AVCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "bmi\n",
      "avg_glucose_level\n",
      "work_type_Self-employed\n",
      "smoking_status_never smoked\n"
     ]
    }
   ],
   "source": [
    "importances = tree.feature_importances_\n",
    "importances_indices = np.argsort(importances)[::-1]\n",
    "importances_indices = importances_indices[:5]\n",
    "\n",
    "colunas = list(df_features.head(0))\n",
    "\n",
    "for i in range(5):\n",
    "    print(colunas[importances_indices[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa abaixo, ocorre a implementação de um algoritmo de treinamento por meio de regressão linear utilizando gradiente descendente para encontrar os valores ótimos dos parâmetros w (vetor de pesos) e b (bias).\n",
    "\n",
    "A primeira função utilizada pelo algoritmo é a \"loss\". Esse método recebe de um conjunto de parâmetros w, b e pontos para calcular um Y estimado, ou seja, gerar um previsão. Isso occore por meio de um cálculo semelhante a uma função de primeiro grau, sendo w um vetor de coefientes ângulares e b um coeficiente linear. Logo após gerar uma previsão, utiliza o parametro val para calcular o MSE: Média dos erros quadráticos entre previsão e valor alvo. Por fim, retorna esse MSE.\n",
    "\n",
    "A função \"grad\" é usada para calcular o gradiente da função loss em relação aos parâmetros w e b. O gradiente é uma medida da inclinação da função de perda em relação aos parâmetros do modelo. O gradiente nos fornece a direção na qual a função de perda está aumentando mais rapidamente. No caso do gradiente descendente, usamos essa informação para atualizar os parâmetros do modelo na direção oposta ao gradiente, de modo que a função de perda seja minimizada.\n",
    "\n",
    "Define-se o conjunto de treinamento X e os valores alvo Y. O vetor de pesos w é inicializado aleatoriamente, e o bias b é definido como 0.5. O valor do hiperparâmetro alpha é definido como 10^-5.\n",
    "\n",
    "Em seguida, o código entra em um loop de treinamento, que executa o gradiente descendente por 10000 iterações. Em cada iteração, o gradiente da função loss é calculado com os parâmetros atuais (w, b, X, Y) usando a função grad, para assim, atualizar os pesos w e o bias b usando o resultado do gradiente e o valor de alpha.\n",
    "\n",
    "Por fim, calcula-se as previsões y_est para o conjunto X teste usando os valores finais dos parâmetros w e b. Em seguida, a acurácia das previsões é calculada usando a função accuracy, por meio da proporção entre previsões certas e erradas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Poda do DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Extração e Tratamento dos dados. Foram levados em consideração apenas os dados capazer de serem transformados em booleanos'''\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv')\n",
    "df = df[df['bmi'].notna()]\n",
    "\n",
    "df_features = df[['gender','hypertension','heart_disease','ever_married','work_type','Residence_type','smoking_status']]\n",
    "df_features = pd.get_dummies(df_features)\n",
    "df_outcome = df[['stroke']]\n",
    "df_outcome = df_outcome.replace(0,-1)\n",
    "df_outcome = pd.get_dummies(df_outcome)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_outcome, train_size=0.5)\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_est):\n",
    "    '''Função que calcula a precisão de um modelo de classificação binária.'''\n",
    "    return np.mean(np.sign(y_test)==np.sign(y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(parametros):\n",
    "    w, b, pontos, val = parametros\n",
    "    est = w.T @ pontos + b\n",
    "    mse = np_.mean((est - val)**2)\n",
    "    return mse\n",
    "\n",
    "g = grad(loss)\n",
    "\n",
    "X = (X_train.T).astype(float)\n",
    "Y = y_train.astype(float)\n",
    "\n",
    "w = np.random.randn(X.shape[0],1)\n",
    "b = 0.1\n",
    "alpha = 10**-5\n",
    "\n",
    "for n in range(1000):\n",
    "    grad_ = g((w, b, X, Y))\n",
    "    w -= alpha*grad_[0]\n",
    "    b -= alpha*grad_[1]\n",
    "\n",
    "y_est = w.T @ X + b\n",
    "pred = accuracy(y_test, y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo com regressão linear: 36.67%\n",
      "Acurácia da hipótese nula: 42.58%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acurácia do modelo com regressão linear: {pred*100:.2f}%\")\n",
    "print(f\"Acurácia da hipótese nula: {accur_0*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nossos testes, o desempenho do algoritmo de predição treinado por meio de regressão linear ficou próximo dos 40% de acurácia, abaixo ao resultado encotrado pela hipótese nula. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datores que mais provavelmente estão ligados a ter AVCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_type_Self-employed\n",
      "work_type_Private\n",
      "work_type_Govt_job\n",
      "work_type_children\n",
      "hypertension\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "mais_imp = []\n",
    "for i in range(5):\n",
    "    mais_imp.append(X.columns[np.argsort(w.T)[0][-i]])\n",
    "\n",
    "colunas = list(df_features.head(0))\n",
    "\n",
    "for i in range(5):\n",
    "    print(colunas[mais_imp[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com poda do DATAFRAME (balancemaento de dados para strokes e para não strokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Extração e Tratamento dos dados. Foram levados em consideração apenas os dados capazer de serem transformados em booleanos'''\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv')\n",
    "df = df[df['bmi'].notna()]\n",
    "df = pd.concat([df[df['stroke'] == 0].head(len(df[df['stroke'] == 1])), df[df['stroke'] == 1]])\n",
    "\n",
    "df_features = df[['gender','hypertension','heart_disease','ever_married','work_type','Residence_type','smoking_status']]\n",
    "df_features = pd.get_dummies(df_features)\n",
    "df_outcome = df[['stroke']]\n",
    "df_outcome = df_outcome.replace(0,-1)\n",
    "df_outcome = pd.get_dummies(df_outcome)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_outcome, train_size=0.5)\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_est):\n",
    "    '''Função que calcula a precisão de um modelo de classificação binária.'''\n",
    "    return np.mean(np.sign(y_test)==np.sign(y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(parametros):\n",
    "    w, b, pontos, val = parametros\n",
    "    est = w.T @ pontos + b\n",
    "    mse = np_.mean((est - val)**2)\n",
    "    return mse\n",
    "\n",
    "g = grad(loss)\n",
    "\n",
    "X = (X_train.T).astype(float)\n",
    "Y = y_train.astype(float)\n",
    "\n",
    "w = np.random.randn(X.shape[0],1)\n",
    "b = 0.1\n",
    "alpha = 10**-5\n",
    "\n",
    "for n in range(10000):\n",
    "    grad_ = g((w, b, X, Y))\n",
    "    w -= alpha*grad_[0]\n",
    "    b -= alpha*grad_[1]\n",
    "\n",
    "y_est = w.T @ X + b\n",
    "pred = accuracy(y_test, y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo com regressão linear: 50.25%\n",
      "Acurácia da hipótese nula: 42.58%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acurácia do modelo com regressão linear: {pred*100:.2f}%\")\n",
    "print(f\"Acurácia da hipótese nula: {accur_0*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nossos testes, o desempenho do algoritmo de predição treinado por meio de regressão linear ficou próximo dos 50% de acurácia, levemente acima do resultado encotrado pela hipótese nula. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datores que mais provavelmente estão ligados a ter AVCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_Female\n",
      "work_type_Self-employed\n",
      "gender_Male\n",
      "ever_married_No\n",
      "work_type_Never_worked\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "mais_imp = []\n",
    "for i in range(5):\n",
    "    mais_imp.append(X.columns[np.argsort(w.T)[0][-i]])\n",
    "\n",
    "colunas = list(df_features.head(0))\n",
    "\n",
    "for i in range(5):\n",
    "    print(colunas[mais_imp[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
